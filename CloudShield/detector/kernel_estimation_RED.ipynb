{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if '/home/zechengh/Mastik/ad/detector/' not in sys.path:\n",
    "    sys.path.append('/home/zechengh/Mastik/ad/detector/')\n",
    "from collections import OrderedDict\n",
    "    \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "import ADbenchmark\n",
    "import LSTMAD\n",
    "\n",
    "import json\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Do not write .pyc\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "# Reload code when code is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "id_to_feature = utils.id_to_feature\n",
    "for k, v in id_to_feature.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_feature = utils.id_to_feature\n",
    "data = collections.defaultdict(collections.defaultdict)\n",
    "\n",
    "for bg_program in ['none', 'mysql', 'webserver', 'streamserver', 'mltrain', 'mapreduce']:\n",
    "    data_dir = 'perf/data/{bg_program}_same_core/10000us/'.format(bg_program=bg_program)\n",
    "    for f in os.listdir(data_dir):\n",
    "        if f.endswith('.npy'):\n",
    "            file_name = f.split('.')[0]\n",
    "            data[bg_program][file_name] = np.load(os.path.join(data_dir, f))\n",
    "\n",
    "feature_list = utils.FeatureSelect.feature_list\n",
    "\n",
    "print(\"Used features:\")\n",
    "for i in feature_list:\n",
    "    print(id_to_feature[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['mysql'] = torch.load(\"detector/checkpoints/AnomalyDetectorMysql.ckpt\")\n",
    "models['streamserver'] = torch.load(\"detector/checkpoints/AnomalyDetectorSS.ckpt\")\n",
    "models['webserver'] = torch.load(\"detector/checkpoints/AnomalyDetectorWS.ckpt\")\n",
    "models['mltrain'] = torch.load(\"detector/checkpoints/AnomalyDetectorMLtrain.ckpt\")\n",
    "models['merged'] = torch.load(\"detector/checkpoints/AnomalyDetectorMerged.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import concurrent\n",
    "\n",
    "model_name = 'merged'\n",
    "model = models[model_name]\n",
    "pred_errors = collections.defaultdict(collections.defaultdict)\n",
    "\n",
    "for bg_program in data.keys(): \n",
    "    for file_name in data[bg_program].keys():\n",
    "        \n",
    "        data_in = model.normalize(np.float32(data[bg_program][file_name][:, feature_list]))\n",
    "        data_in_tensor = torch.tensor(data_in)\n",
    "        \n",
    "        _, pred = model._get_reconstruction_error(\n",
    "            data_in_tensor,\n",
    "            gpu=True,\n",
    "        )\n",
    "        \n",
    "        pred = pred[:, 0, :].detach().cpu().numpy()\n",
    "        pred_errors[bg_program][file_name] = data_in[1:, :]-pred\n",
    "        \n",
    "        Path(f'detector/preprocessed/pred_errors/{model_name}/{bg_program}').mkdir(parents=True, exist_ok=True)\n",
    "        np.save(f'detector/preprocessed/pred_errors/{model_name}/{bg_program}/{file_name}', pred_errors[bg_program][file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "import concurrent\n",
    "\n",
    "sampling = True\n",
    "training_data = []\n",
    "testing_data = collections.defaultdict(list)\n",
    "\n",
    "pred_errors = collections.defaultdict(collections.defaultdict)\n",
    "model_name = 'merged'\n",
    "\n",
    "for bg_program in ['none', 'mysql', 'webserver', 'streamserver', 'mltrain', 'mapreduce']:\n",
    "    data_dir = f'detector/preprocessed/pred_errors/{model_name}/{bg_program}/'.format(bg_program=bg_program)\n",
    "    for f in os.listdir(data_dir):\n",
    "        if f.endswith('.npy'):\n",
    "            file_name = f.split('.')[0]\n",
    "            pred_errors[bg_program][file_name] = np.load(os.path.join(data_dir, f))\n",
    "\n",
    "for bg_program in pred_errors.keys():\n",
    "    d = pred_errors[bg_program]['ref_and_val_normal']\n",
    "    if sampling:\n",
    "        sampling_idx = np.random.randint(low=0, high=len(d), size=1000)\n",
    "        d = d[sampling_idx, :]\n",
    "        \n",
    "    training_data.append(d)\n",
    "\n",
    "training_data = np.concatenate(training_data, axis=0)\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(training_data)\n",
    "th = 5.0\n",
    "\n",
    "for bg_program in pred_errors.keys():\n",
    "    \n",
    "    # Accelerate with multiprocessing\n",
    "    def anomaly_detection(kde, data, bg_program, file_name):  \n",
    "        kde_result = kde.score_samples(data)\n",
    "        total = np.float32(len(kde_result))\n",
    "        \n",
    "        Path(f'detector/preprocessed/kde/{model_name}/{bg_program}').mkdir(parents=True, exist_ok=True)\n",
    "        np.save(f'detector/preprocessed/kde/{model_name}/{bg_program}/{file_name}', kde_result)\n",
    "        print(bg_program, file_name, kde_result)\n",
    "        \n",
    "        return 1\n",
    "        \n",
    "    executor = concurrent.futures.ProcessPoolExecutor(20)\n",
    "    futures = [executor.submit(anomaly_detection, kde, pred_errors[bg_program][file_name], bg_program, file_name) for file_name in pred_errors[bg_program].keys()]\n",
    "    concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'merged'\n",
    "kde_results = collections.defaultdict(collections.defaultdict)\n",
    "stats = collections.defaultdict(list)\n",
    "\n",
    "predicts = []\n",
    "ked_result_all = []\n",
    "for bg_program in ['mysql', 'webserver', 'streamserver', 'mltrain', 'mapreduce']:\n",
    "    for file_name in [\n",
    "            'train_normal',\n",
    "            'train_normal_with_gpg',\n",
    "            'train_normal_with_gcc',\n",
    "            'train_normal_with_mcf',\n",
    "            'train_normal_with_libquantum',\n",
    "            ]:\n",
    "\n",
    "        kde_result = np.load(f'detector/preprocessed/kde/{model_name}/{bg_program}/{file_name}.npy')\n",
    "        ked_result_all.append(kde_result)\n",
    "        \n",
    "ked_result_all = np.array(ked_result_all).reshape(-1)\n",
    "ked_result_all.sort()\n",
    "\n",
    "# Use the 10 percentile as threshold (10% of training normal is incorrectly classified as abnormal)\n",
    "print(\"Mean \", np.mean(ked_result_all), \"Std\", np.std(ked_result_all))\n",
    "plt.hist(ked_result_all, bins=np.linspace(-20, 0, 100))\n",
    "print(\"Threshold \", np.percentile(ked_result_all, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "model_name = 'merged'\n",
    "th = -3.3\n",
    "\n",
    "kde_results = collections.defaultdict(collections.defaultdict)\n",
    "\n",
    "predicts = []\n",
    "for bg_program in ['mysql', 'webserver', 'streamserver', 'mltrain', 'mapreduce']: #'webserver'\n",
    "    for file_name in [\n",
    "            'test_normal',\n",
    "            'test_normal_with_gpg',\n",
    "            'test_normal_with_gcc',\n",
    "            'test_normal_with_mcf',\n",
    "            'test_normal_with_libquantum',\n",
    "            'test_abnormal_l1pp',\n",
    "            'test_abnormal_l3pp',\n",
    "            'test_abnormal_fr',\n",
    "            'test_abnormal_ff',\n",
    "            'test_abnormal_spectrev1',\n",
    "            'test_abnormal_spectrev2',\n",
    "            'test_abnormal_spectrev3',\n",
    "            'test_abnormal_spectrev4',\n",
    "            'test_abnormal_bufferoverflow',\n",
    "            'test_abnormal_l1pp_with_gpg',\n",
    "            'test_abnormal_l3pp_with_gpg',\n",
    "            'test_abnormal_fr_with_gpg',\n",
    "            'test_abnormal_ff_with_gpg',\n",
    "            'test_abnormal_spectrev1_with_gpg',\n",
    "            'test_abnormal_spectrev2_with_gpg',\n",
    "            'test_abnormal_spectrev3_with_gpg',\n",
    "            'test_abnormal_spectrev4_with_gpg',\n",
    "            'test_abnormal_bufferoverflow_with_gpg',\n",
    "            'test_abnormal_l1pp_with_gcc',\n",
    "            'test_abnormal_l3pp_with_gcc',\n",
    "            'test_abnormal_fr_with_gcc',\n",
    "            'test_abnormal_ff_with_gcc',\n",
    "            'test_abnormal_spectrev1_with_gcc',\n",
    "            'test_abnormal_spectrev2_with_gcc',\n",
    "            'test_abnormal_spectrev3_with_gcc',\n",
    "            'test_abnormal_spectrev4_with_gcc',\n",
    "            'test_abnormal_bufferoverflow_with_gcc',\n",
    "            'test_abnormal_l1pp_with_libquantum',\n",
    "            'test_abnormal_l3pp_with_libquantum',\n",
    "            'test_abnormal_fr_with_libquantum',\n",
    "            'test_abnormal_ff_with_libquantum',\n",
    "            'test_abnormal_spectrev1_with_libquantum',\n",
    "            'test_abnormal_spectrev2_with_libquantum',\n",
    "            'test_abnormal_spectrev3_with_libquantum',\n",
    "            'test_abnormal_spectrev4_with_libquantum',\n",
    "            'test_abnormal_bufferoverflow_with_libquantum',\n",
    "\n",
    "            ]:\n",
    "\n",
    "        kde_result = np.load(f'detector/preprocessed/kde/{model_name}/{bg_program}/{file_name}.npy')\n",
    "        total = float(len(kde_result))\n",
    "        \n",
    "        pred_normal = np.sum(kde_result >= th) / total\n",
    "        pred_abnormal = np.sum(kde_result < th) / total\n",
    "        \n",
    "        predicts.append([\n",
    "            bg_program, file_name, pred_normal, pred_abnormal,\n",
    "            np.mean(kde_result), np.std(kde_result), np.min(kde_result), np.max(kde_result),\n",
    "            np.percentile(kde_result, 10), np.percentile(kde_result, 90)])\n",
    "\n",
    "columns = ['Workload', 'Test Case', 'Pred normal', 'Pred abnormal', 'Mean', 'Std', 'Min', 'Max', '10%', '90%']\n",
    "print(pd.DataFrame(predicts, columns=columns))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
